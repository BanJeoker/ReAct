{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d490b548-63c9-4a01-8723-2d7b340989b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Content, GenerativeModel, Part  \n",
    "from google.cloud import aiplatform  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554337d5-3773-4f2a-9650-f001e8d4bdcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file=open(\"data/react_intro.txt\",\"r\")\n",
    "info_txt=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c771c494-cee8-4715-b9a1-ae75f3b0c522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt=f\"\"\"\n",
    "I am talking about {info_txt}. What am I talking about\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d24935-b4e5-4771-ad36-b691dbe395f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are talking about **ReAct prompting**, a specific prompting technique designed to enhance the reasoning and action-taking abilities of large language models (LLMs).  It goes beyond simply generating text by encouraging the model to approach problems in a more structured and deliberate way, similar to how humans might tackle them.  This involves a back-and-forth process where the model reasons about the problem, formulates a plan of action, takes action (like querying a knowledge base or using a tool), observes the outcome, and then refines its reasoning and subsequent actions based on the feedback.  This iterative approach allows the model to handle more complex and dynamic tasks more effectively.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "response=model.generate_content([prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d5d4de-a558-4eec-9c01-cc350b6e14cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are talking about **ReAct prompting**, a technique for interacting with Large Language Models (LLMs) that encourages them to perform complex reasoning and generate actionable plans.  It's a way to improve the decision-making capabilities of AI by guiding it through a thought process similar to how humans solve problems.  This contrasts with simpler prompting methods that only ask for a direct answer without explicit consideration of the reasoning steps involved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "response=model.generate_content([prompt,info_txt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8792e5c-274d-47ec-a81f-44878f3e841c",
   "metadata": {},
   "source": [
    "# decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da9b38b9-c102-4708-a037-ffdd9a6d921b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    def __init__(self, name, fn, fn_signature):\n",
    "        self.name = name\n",
    "        self.fn = fn\n",
    "        self.fn_signature = fn_signature\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.fn_signature\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"Running tool: {self.name}, fn_signature:{self.fn_signature}\")\n",
    "        return self.fn()  # Execute the original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc44a069-904c-41a2-8474-f58f9c1e3cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# def tool(fn):\n",
    "#     def wrapper():\n",
    "#         # Simulating function signature extraction\n",
    "#         fn_signature = {\"name\": fn.__name__, \"doc\": fn.__doc__}\n",
    "        \n",
    "#         # Create the Tool object\n",
    "#         return Tool(\n",
    "#             name=fn_signature[\"name\"],\n",
    "#             fn=fn,\n",
    "#             fn_signature=json.dumps(fn_signature)\n",
    "#         )\n",
    "    \n",
    "#     return wrapper()\n",
    "\n",
    "def tool(fn):\n",
    "    fn_signature = {\"name\": fn.__name__, \"doc\": fn.__doc__}\n",
    "    return Tool(\n",
    "            name=fn_signature[\"name\"],\n",
    "            fn=fn,\n",
    "            fn_signature=json.dumps(fn_signature)\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f249d6-bfa2-474e-9fb1-ed6a7482f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Tool:\n",
    "    def __init__(self, name, fn, fn_signature):\n",
    "        self.name = name\n",
    "        self.fn = fn\n",
    "        self.fn_signature = fn_signature\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.fn_signature\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"Running tool: {self.name}, fn_signature:{self.fn_signature}\")\n",
    "        return self.fn()  # Execute the original function\n",
    "    \n",
    "def tool(fn):\n",
    "    fn_signature = {\"name\": fn.__name__, \"doc\": fn.__doc__}\n",
    "    return Tool(\n",
    "            name=fn_signature[\"name\"],\n",
    "            fn=fn,\n",
    "            fn_signature=json.dumps(fn_signature)\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def say_hello():\n",
    "    '''\n",
    "    this is the doc\n",
    "    '''\n",
    "    print(\"Hello!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9865c2eb-0028-40b7-ba94-728c6e56515c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92129eac-c75f-4961-8c93-0ab2940cc2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Tool"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(say_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "704ca13a-0507-481e-a642-3e213afd78cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"say_hello\", \"doc\": \"\\\\n    this is the doc\\\\n    \"}'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "say_hello.fn_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bfa2a239-638d-46e1-8360-5477756efbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def greet(self):\n",
    "        print(\"Hello from MyClass!\")\n",
    "\n",
    "# Now manually apply the tool decorator to MyClass's method\n",
    "my_instance = MyClass()\n",
    "mygreet = tool(my_instance.greet)\n",
    "\n",
    "# # Call the method (now wrapped in the Tool class)\n",
    "# my_instance.greet.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f689991-63b7-41ca-a17a-503f8570773c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tool: greet, fn_signature:{\"name\": \"greet\", \"doc\": null}\n",
      "Hello from MyClass!\n"
     ]
    }
   ],
   "source": [
    "mygreet.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7465c6f9-d573-4129-a38c-5a838e69a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def say_hello(x: int, y: str) -> bool:\n",
    "# {'x': int, 'y': str, 'return': bool}\n",
    "\n",
    "    '''\n",
    "    this is the doc\n",
    "    '''\n",
    "    print(\"Hello!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e8ffaab-a658-47eb-ba6e-20d856cd3916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': int, 'y': str, 'return': bool}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "say_hello.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fa5c71-bfe5-422a-94c0-c169c792d48c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src folder to the Python path\n",
    "# sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Now you can import the function or class from tool.py\n",
    "from src.tool import get_fn_signature  # Replace with the actual function name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c263afdf-3cfd-491f-ac12-cf292e62f29a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function src.tool.get_fn_signature(fn: Callable) -> dict>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fn_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceded800-e20c-4607-8c7d-0abcb503b0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'say_hello',\n",
       " 'description': '\\n    this is the doc\\n    ',\n",
       " 'parameters': {'properties': {'x': {'type': 'int'}, 'y': {'type': 'str'}}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fn_signature(say_hello)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
