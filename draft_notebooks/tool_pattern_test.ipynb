{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecbdcbe7-13b5-4b2c-9dfe-4c074e23664b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Content, GenerativeModel, Part  \n",
    "from google.cloud import aiplatform  \n",
    "from IPython.display import Markdown,display,HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e62afc-44ba-4278-bc3a-740d4635106b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Minnesota Vikings have appeared in four Super Bowls but have not won any of them.  They lost Super Bowl IV (to the Kansas City Chiefs), Super Bowl VIII (to the Miami Dolphins), Super Bowl IX (to the Pittsburgh Steelers), and Super Bowl XI (to the Oakland Raiders).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question='how many superbowl Vikings has won?'\n",
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "response = model.generate_content([question], generation_config={\"temperature\":0})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48c5c82-7983-4b6c-9ebe-155f0899910d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rams franchise has won a total of **four** Super Bowls:\n",
      "\n",
      "* **Super Bowl XXXIV (2000)**:  St. Louis Rams defeated the Tennessee Titans.\n",
      "* **Super Bowl LVI (2022)**: Los Angeles Rams defeated the Cincinnati Bengals.\n",
      "* **Super Bowl XIV (1980)**: Los Angeles Rams lost to the Pittsburgh Steelers.\n",
      "* **Super Bowl XXXVI (2002)**: St. Louis Rams lost to the New England Patriots.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test connection first\n",
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "response = model.generate_content([\"\"\"how many superbowls has Rams won\"\"\"], generation_config={\"temperature\":0})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8bd2dab-3de4-420e-9270-da80b59e13df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Rams have won **two** Super Bowls:\n",
      "\n",
      "* **Super Bowl XXXIV (2000):** Rams 23, Tennessee Titans 16\n",
      "* **Super Bowl LVI (2022):** Rams 23, Cincinnati Bengals 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "response = model.generate_content([\"\"\"\n",
    "how many superbowls has Rams won, and the score\"\"\"], generation_config={\"temperature\":0})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09cfdc-bd64-444b-aef1-c3d6571d0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "response = model.generate_content([\"\"\"\n",
    "how many superbowls has Rams won, and the score, \n",
    "and how many points they win by\"\"\"], generation_config={\"temperature\":0})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4c7a35-265f-42c4-b781-cb1dce1d3824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Rams have won **2** Super Bowls. \n",
      "\n",
      "* **Super Bowl XXXIV (2000):** Defeated the Tennessee Titans 23-16\n",
      "* **Super Bowl LVI (2022):** Defeated the Cincinnati Bengals 23-20 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "response = model.generate_content([\"\"\"how many superbowls has Rams won\"\"\"], generation_config={\"temperature\":0})\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbd136-deff-4843-9928-11e7215fcb9b",
   "metadata": {},
   "source": [
    "<font color='red'> gemini 002 is incorrect </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8af323a-0a64-48fb-8063-084f1de2936d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're asking about the Super Bowl winner in the year following each Rams victory:\\n\\n* **After Super Bowl XXXIV (2000):** The Baltimore Ravens won Super Bowl XXXV in 2001.\\n* **After Super Bowl LVI (2018):** The New England Patriots won Super Bowl LIII in 2019.\\n* **After Super Bowl LVI (2022):** The Kansas City Chiefs won Super Bowl LVII in 2023. \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# deliberately provide a incorrect answer to the model to test whether history is indeed being used, the rams didn't win the 2018 superbowls\n",
    "model_answer='''\n",
    "The Los Angeles Rams have won **3** Super Bowls. \n",
    "\n",
    "* **Super Bowl XXXIV (2000):** Defeated the Tennessee Titans 23-16\n",
    "* **Super Bowl LVI (2018):** Defeated the Philadephia Eagles 10-7 \n",
    "* **Super Bowl LVI (2022):** Defeated the Cincinnati Bengals 23-20 \n",
    "'''\n",
    "messages=[\n",
    "    Content(role='user', parts=[Part.from_text('how many superbowls has Rams won')]),\n",
    "    Content(role='model', parts=[Part.from_text(model_answer)]),\n",
    "    Content(role='user', parts=[Part.from_text('who won the next year')])\n",
    "   \n",
    "]\n",
    "model = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "\n",
    "response = model.generate_content(contents=messages, generation_config={\"temperature\":0}) \n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1704f3e6-44cf-4f22-b63b-0e2b28eae0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute(client, messages: list, generation_config={\"temperature\":0}) -> str:\n",
    "    \"\"\"\n",
    "    Sends a request to the client's `generate_content` method to interact with the language model.\n",
    "\n",
    "    Args:\n",
    "        client (Gemini model): The gemini model\n",
    "        messages (list[Content]): A list of Content as chat history\n",
    "        generation_config: generation configuration\n",
    "        \n",
    "    Returns:\n",
    "        str: The content of the model's response.\n",
    "    \"\"\"\n",
    "    response = client.generate_content(contents=messages, generation_config=generation_config) \n",
    "    return response.text\n",
    "\n",
    "\n",
    "def create_single_text_Content(role, text):\n",
    "    '''\n",
    "    Create a Content object for history, containing only one part, which is a text\n",
    "    Args:\n",
    "        role: can be either 'user' or 'model'\n",
    "        text: the content\n",
    "    Return: Content\n",
    "    '''\n",
    "    return Content(role=role, parts=[Part.from_text(text)])\n",
    "    \n",
    "\n",
    "def update_chat_history(history: list, msg: str, role: str):\n",
    "    \"\"\"\n",
    "    Updates the chat history by appending the latest response.\n",
    "\n",
    "    Args:\n",
    "        history (list): The list representing the current chat history.\n",
    "        msg (str): The message to append.\n",
    "        role (str): The role type ('user' or 'model')\n",
    "    \"\"\"\n",
    "    history.append(create_single_text_Content(text=msg, role=role))\n",
    "\n",
    "\n",
    "class ChatHistory(list):\n",
    "    def __init__(self, messages: list | None = None, total_length: int = -1):\n",
    "        \"\"\"\n",
    "        Initialise the list with a fixed total length.\n",
    "\n",
    "        Args:\n",
    "            messages (list | None): A list of initial messages, each message is a Content\n",
    "            total_length (int): The maximum number of messages the chat history can hold.\n",
    "        \"\"\"\n",
    "        if messages is None:\n",
    "            messages = []\n",
    "\n",
    "        super().__init__(messages)\n",
    "        self.total_length = total_length\n",
    "\n",
    "    def append(self, msg):\n",
    "        \"\"\"Add a Content to the queue.\n",
    "        Args:\n",
    "            msg (Content): The message to be added to the queue\n",
    "        \"\"\"\n",
    "        if len(self) == self.total_length:\n",
    "            self.pop(0)\n",
    "        super().append(msg)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce847a5-aab1-48f5-9d59-56889155b38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TagContentResult:\n",
    "    \"\"\"\n",
    "    A data class to represent the result of extracting tag content.\n",
    "\n",
    "    Attributes:\n",
    "        content (List[str]): A list of strings containing the content found between the specified tags.\n",
    "        found (bool): A flag indicating whether any content was found for the given tag.\n",
    "    \"\"\"\n",
    "\n",
    "    content: list[str]\n",
    "    found: bool\n",
    "\n",
    "\n",
    "def extract_tag_content(text: str, tag: str) -> TagContentResult:\n",
    "    \"\"\"\n",
    "    Extracts all content enclosed by specified tags (e.g., <thought>, <response>, etc.).\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The input string containing multiple potential tags.\n",
    "        tag (str): The name of the tag to search for (e.g., 'thought', 'response').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the following keys:\n",
    "            - 'content' (list): A list of strings containing the content found between the specified tags.\n",
    "            - 'found' (bool): A flag indicating whether any content was found for the given tag.\n",
    "    \"\"\"\n",
    "    # Build the regex pattern dynamically to find multiple occurrences of the tag\n",
    "    tag_pattern = rf\"<{tag}>(.*?)</{tag}>\"\n",
    "\n",
    "    # Use findall to capture all content between the specified tag\n",
    "    matched_contents = re.findall(tag_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the dataclass instance with the result\n",
    "    return TagContentResult(\n",
    "        content=[content.strip() for content in matched_contents],\n",
    "        found=bool(matched_contents),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "999774fd-0cfd-4a3d-8c00-29d51e83b8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src import tool_functions\n",
    "importlib.reload(tool_functions)\n",
    "from src.tool_functions import Tool, get_fn_signature, validate_arguments, convert_to_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "131eb33f-1fa7-4646-9da1-cc6eeb0c3967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_current_weather(location: str, unit: str):\n",
    "    \"\"\"\n",
    "    Get the current weather in a given location\n",
    "    \n",
    "    Args:\n",
    "        location (str): The city and state, e.g. Madrid, Barcelona\n",
    "        unit (str): The unit. It can take two values; \"Felsius\", \"Fahrenheit\"\n",
    "    \"\"\"\n",
    "    if location == \"Charlotte\":\n",
    "        return json.dumps({\"temperature\": 25, \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"temperature\": 58, \"unit\": unit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1835a65-97c5-4d50-b27c-5860d87cb18b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"temperature\": 25, \"unit\": \"Fahrenheit\"}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(location=\"Charlotte\", unit=\"Fahrenheit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acdb4d52-677f-4ee4-819a-2a571e9a044e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_tool = convert_to_tool(get_current_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb9a9ca6-0c44-4fa6-9a94-96c96f6a4846",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_weather',\n",
       " 'description': '\\n    Get the current weather in a given location\\n    \\n    Args:\\n        location (str): The city and state, e.g. Madrid, Barcelona\\n        unit (str): The unit. It can take two values; \"Felsius\", \"Fahrenheit\"\\n    ',\n",
       " 'parameters': {'properties': {'location': {'type': 'str'},\n",
       "   'unit': {'type': 'str'}}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(weather_tool.fn_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f66e1-ae27-4361-b7ed-2e7d39bd5d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "402a03bd-1908-4abe-9e41-86ddc8677db3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: green;\">\n",
       "Using Tool: get_current_weather</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: green;\">\n",
       "Tool call dict: \n",
       "{'name': 'get_current_weather', 'arguments': {'location': 'Charlotte', 'unit': 'Fahrenheit'}, 'id': 1}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: green;\">\n",
       "Tool result: \n",
       "{\"temperature\": 25, \"unit\": \"Fahrenheit\"}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '{\"temperature\": 25, \"unit\": \"Fahrenheit\"}'}\n",
      "final answer!!!!!!!!\n",
      "The weather in Charlotte is 25 degrees Fahrenheit. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT= \"\"\"\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug\n",
    "into functions. Pay special attention to the properties 'types'. You should use those types as in a Python dict.\n",
    "For each function call return a json object with function name and arguments within <tool_call></tool_call>\n",
    "XML tags as follows:\n",
    "\n",
    "<tool_call>\n",
    "{\"name\": <function-name>,\"arguments\": <args-dict>,  \"id\": <monotonically-increasing-id>}\n",
    "</tool_call>\n",
    "\n",
    "Here are the available tools:\n",
    "\n",
    "<tools>\n",
    "%s\n",
    "</tools>\n",
    "\n",
    "if none of the functions is related to the question, answer the question using your own knowledge.\n",
    "if you are provided with observations, you may answer the question based on that observation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ToolAgent:\n",
    "    \n",
    "    def __init__(self, tools: Tool | list[Tool]) -> None:\n",
    "        \n",
    "        self.client = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "        self.tools = tools if isinstance(tools, list) else [tools]\n",
    "        self.tools_dict = {tool.name: tool for tool in self.tools}\n",
    "        \n",
    "\n",
    "    def add_tool_signatures(self) -> str:\n",
    "        \"\"\"\n",
    "        Collects the function signatures of all available tools.\n",
    "\n",
    "        Returns:\n",
    "            str: A concatenated string of all tool function signatures in JSON format.\n",
    "        \"\"\"\n",
    "        \n",
    "        return \"\".join([tool.fn_signature for tool in self.tools])\n",
    "\n",
    "    def process_tool_calls(self, tool_calls_content: list) -> dict:\n",
    "        \"\"\"\n",
    "        Processes each tool call, validates arguments, executes the tools, and collects results.\n",
    "\n",
    "        Args:\n",
    "            tool_calls_content (list): List of strings, each representing a tool call in JSON format.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary where the keys are tool call IDs and values are the results from the tools.\n",
    "        \"\"\"\n",
    "        observations = {}\n",
    "        for tool_call_str in tool_calls_content:\n",
    "            tool_call = json.loads(tool_call_str)\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool = tools_dict[tool_name]\n",
    "\n",
    "            print_in_color(text=f\"\\nUsing Tool: {tool_name}\", color='green')\n",
    "\n",
    "            validated_tool_call = validate_arguments(\n",
    "                tool_call, json.loads(tool.fn_signature)\n",
    "            )\n",
    "            print_in_color(text=f\"\\nTool call dict: \\n{validated_tool_call}\", color='green')\n",
    "\n",
    "\n",
    "            result = tool.run(**validated_tool_call[\"arguments\"])\n",
    "\n",
    "            print_in_color(text=f\"\\nTool result: \\n{result}\", color='green')\n",
    "\n",
    "\n",
    "            observations[validated_tool_call[\"id\"]] = result\n",
    "\n",
    "        return observations\n",
    "    \n",
    "    def run(self, user_msg: str,):\n",
    "        \"\"\"\n",
    "        Handles the full process of interacting with the language model and executing a tool based on user input.\n",
    "\n",
    "        Args:\n",
    "            user_msg (str): The user's message that prompts the tool agent to act.\n",
    "\n",
    "        Returns:\n",
    "            str: The final output after executing the tool and generating a response from the model.\n",
    "        \"\"\"\n",
    "            \n",
    "        chat_history = ChatHistory(\n",
    "            [\n",
    "                create_single_text_Content(\n",
    "                    text=SYSTEM_PROMPT % self.add_tool_signatures(),\n",
    "                    role=\"user\",\n",
    "                ),\n",
    "                create_single_text_Content(\n",
    "                    text=user_msg, \n",
    "                    role=\"user\"\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        response = execute(self.client, messages=chat_history)\n",
    "        tool_calls = extract_tag_content(str(response), \"tool_call\")\n",
    "        \n",
    "                       \n",
    "        if tool_calls.found:\n",
    "            observations = self.process_tool_calls(tool_calls.content)\n",
    "            update_chat_history(history=chat_history, msg=f\"Observation: {observations}\", role=\"user\")\n",
    "        \n",
    "        \n",
    "        print(\"final answer!!!!!!!!\")\n",
    "        \n",
    "        return execute(self.client, messages=chat_history)\n",
    "\n",
    "\n",
    "tool_agent = ToolAgent(tools=[weather_tool])\n",
    "temp=tool_agent.run(\"What is the weather today in Charlotte?\")\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "572b3991-ba93-4fd4-b3f2-8689998d1a14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TagContentResult(content=['{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"Charlotte\", \"unit\": \"Fahrenheit\"}, \"id\": 1}'], found=True)\n"
     ]
    }
   ],
   "source": [
    "tag_content=extract_tag_content(temp, \"tool_call\")\n",
    "print(tag_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab40da3-a1f1-4120-aaa0-7ca37bed5a92",
   "metadata": {},
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2a872bad-a97e-464a-b99a-164db1bb7136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"Charlotte\", \"unit\": \"Fahrenheit\"}, \"id\": 1}']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_content.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f4edf07-815d-404e-80c1-444caac0923f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_in_color(text, color):\n",
    "    display(HTML(f'<span style=\"color: {color};\">{text}</span>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "109c6e95-9b46-4384-8ec6-98827c74d31b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_current_weather': <src.tool_functions.Tool object at 0x7fc172354340>}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: green;\">\n",
       "Using Tool: get_current_weather</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: green;\">\n",
       "Tool call dict: \n",
       "{'name': 'get_current_weather', 'arguments': {'location': 'Charlotte', 'unit': 'Fahrenheit'}, 'id': 1}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Charlotte', 'unit': 'Fahrenheit'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color: green;\">\n",
       "Tool result: \n",
       "{\"temperature\": 25, \"unit\": \"Fahrenheit\"}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '{\"temperature\": 25, \"unit\": \"Fahrenheit\"}'}\n",
      "{1: '{\"temperature\": 25, \"unit\": \"Fahrenheit\"}'}\n"
     ]
    }
   ],
   "source": [
    "tools=[weather_tool]\n",
    "tools_dict = {tool.name: tool for tool in tools}\n",
    "print(tools_dict)\n",
    "\n",
    "\n",
    "\n",
    "def process_tool_calls( tool_calls_content: list) -> dict:\n",
    "   \n",
    "    \"\"\"\n",
    "    Processes each tool call, validates arguments, executes the tools, and collects results.\n",
    "\n",
    "    Args:\n",
    "        tool_calls_content (list): List of strings, each representing a tool call in JSON format.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are tool call IDs and values are the results from the tools.\n",
    "    \"\"\"\n",
    "    \n",
    "    observations = {}\n",
    "    for tool_call_str in tool_calls_content:\n",
    "        tool_call = json.loads(tool_call_str)\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool = tools_dict[tool_name]\n",
    "\n",
    "        print_in_color(text=f\"\\nUsing Tool: {tool_name}\", color='green')\n",
    "\n",
    "        validated_tool_call = validate_arguments(\n",
    "            tool_call, json.loads(tool.fn_signature)\n",
    "        )\n",
    "        print_in_color(text=f\"\\nTool call dict: \\n{validated_tool_call}\", color='green')\n",
    "        \n",
    "\n",
    "        result = tool.run(**validated_tool_call[\"arguments\"])\n",
    "        \n",
    "        print(validated_tool_call[\"arguments\"])\n",
    "        \n",
    "        print_in_color(text=f\"\\nTool result: \\n{result}\", color='green')\n",
    "\n",
    "\n",
    "        observations[validated_tool_call[\"id\"]] = result\n",
    "        print(observations)\n",
    "        \n",
    "    return observations\n",
    "\n",
    "print(process_tool_calls(tool_calls_content=tag_content.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a0eec086-67ba-4fcb-a0ea-84d960fcdfbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'get_current_weather', 'arguments': {'location': 'Charlotte', 'unit': 'Fahrenheit'}, 'id': 1}\n",
      "{'name': 'get_current_weather', 'description': '\\n    Get the current weather in a given location\\n    \\n    Args:\\n        location (str): The city and state, e.g. Madrid, Barcelona\\n        unit (str): The unit. It can take two values; \"Felsius\", \"Fahrenheit\"\\n    ', 'parameters': {'properties': {'location': {'type': 'str'}, 'unit': {'type': 'str'}}}}\n"
     ]
    }
   ],
   "source": [
    "tool_call = json.loads(tag_content.content[0])\n",
    "print(tool_call)\n",
    "tool_signature=json.loads(weather_tool.fn_signature)\n",
    "print(tool_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5e651b60-8088-4652-a9c7-833a331a77d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': {'type': 'str'}, 'unit': {'type': 'str'}}\n",
      "location Charlotte\n",
      "<class 'str'>\n",
      "unit Fahrenheit\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "properties = tool_signature[\"parameters\"][\"properties\"]\n",
    "print(properties)\n",
    "      \n",
    "# TODO: This is overly simplified but enough for simple Tools.\n",
    "type_mapping = {\n",
    "        \"int\": int,\n",
    "        \"str\": str,\n",
    "        \"bool\": bool,\n",
    "        \"float\": float,\n",
    "}\n",
    "\n",
    "for arg_name, arg_value in tool_call[\"arguments\"].items():\n",
    "    print(arg_name,arg_value)\n",
    "    expected_type = properties[arg_name].get(\"type\")\n",
    "    print(type(expected_type))\n",
    "    \n",
    "    if not isinstance(arg_value, type_mapping[expected_type]):\n",
    "        tool_call[\"arguments\"][arg_name] = type_mapping[expected_type](arg_value)\n",
    "\n",
    "return tool_call\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437be4c-2d14-4ee7-8961-72158a5c5099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed12f6-c0a5-4142-add6-b95d8b79bf58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
